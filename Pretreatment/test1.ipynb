{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a067c73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train/base_features.csv\n",
      "0 0 0:00:00.000981\n",
      "10 1 0:00:00.000981\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3daebba7ef38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mreduce_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffers_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransactions_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduced_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0mgenerate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransactions_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-3daebba7ef38>\u001b[0m in \u001b[0;36mgenerate_features\u001b[1;34m(transactions_file, out_file)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0moutfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"label repeattrips id \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" market chain\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m#iterate through reduced dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import string,os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, date\n",
    "\n",
    "testset = False\n",
    "\n",
    "offers_file = \"offers.csv\"\n",
    "transactions_file = \"./data/t1.csv\"\n",
    "if testset:\n",
    "\thistory_file = \"testHistory.csv\"\n",
    "else:\n",
    "\thistory_file = \"trainHistory.csv\"\n",
    "\n",
    "# will be created\n",
    "reduced_file = \"./data/reduced.csv\" \n",
    "if testset:\n",
    "\tfolder = \"./test/\"\n",
    "else:\n",
    "\tfolder = \"./train/\"\n",
    "out_file = os.path.join(folder, \"base_features.csv\")\n",
    "print(out_file)\n",
    "\n",
    "feature_list = [\"offer_id\", \"never_bought_company\", \"never_bought_category\", \"never_bought_brand\", \\\n",
    "\t\"has_bought_brand_company_category\", \"has_bought_brand_category\", \"has_bought_brand_company\", \\\n",
    "\t\"offer_value\", \"total_spend_all\", \"total_spend_ccb\", \"has_bought_company\", \"has_bought_company_q\", \"has_bought_company_a\", \\\n",
    "\t\"has_bought_company_30\", \"has_bought_company_q_30\", \"has_bought_company_a_30\", \"has_bought_company_60\", \\\n",
    "\t\"has_bought_company_q_60\", \"has_bought_company_a_60\", \"has_bought_company_90\", \"has_bought_company_q_90\", \\\n",
    "\t\"has_bought_company_a_90\", \"has_bought_company_180\", \"has_bought_company_q_180\", \"has_bought_company_a_180\", \\\n",
    "\t\"has_bought_category\", \"has_bought_category_q\", \"has_bought_category_a\", \"has_bought_category_30\", \\\n",
    "\t\"has_bought_category_q_30\", \"has_bought_category_a_30\", \"has_bought_category_60\", \"has_bought_category_q_60\", \\\n",
    "\t\"has_bought_category_a_60\", \"has_bought_category_90\", \"has_bought_category_q_90\", \"has_bought_category_a_90\", \\\n",
    "\t\"has_bought_category_180\", \"has_bought_category_q_180\", \"has_bought_category_a_180\", \"has_bought_brand\", \\\n",
    "\t\"has_bought_brand_q\", \"has_bought_brand_a\", \"has_bought_brand_30\", \"has_bought_brand_q_30\", \"has_bought_brand_a_30\", \\\n",
    "\t\"has_bought_brand_60\", \"has_bought_brand_q_60\", \"has_bought_brand_a_60\", \"has_bought_brand_90\", \"has_bought_brand_q_90\", \\\n",
    "\t\"has_bought_brand_a_90\", \"has_bought_brand_180\", \"has_bought_brand_q_180\", \"has_bought_brand_a_180\"]\n",
    "\n",
    "def reduce_data(offers_file, transactions_file, reduced_file):\n",
    "\tstart = datetime.now()\n",
    "\t#把offer檔案中的catergory.company找出來做成字典(把有提供優惠的公司跟產品找出)\n",
    "\toffers_cat = {}\n",
    "\toffers_co = {}\n",
    "\tfor e, line in enumerate( open(offers_file) ):\n",
    "\t\toffers_cat[ line.split(\",\")[1] ] = 1\n",
    "\t\toffers_co[ line.split(\",\")[3] ] = 1\n",
    "\t#open output file\n",
    "\twith open(reduced_file, \"wb\") as outfile:\n",
    "\t\t#go through transactions file and reduce\n",
    "\t\treduced = 0\n",
    "\t\tfor e, line in enumerate( open(transactions_file) ):\n",
    "\t\t\tif e == 0:\n",
    "\t\t\t\toutfile.write( line.encode() ) #print header\n",
    "\t\t\telse:\n",
    "\t\t\t\t#只寫入catergory跟company有出現在offers字典的\n",
    "\t\t\t\tif line.split(\",\")[3] in offers_cat or line.split(\",\")[4] in offers_co:\n",
    "\t\t\t\t\toutfile.write( line.encode() )\n",
    "\t\t\t\t\treduced += 1\n",
    "\t\t\t#progress  ??\n",
    "\t\t\tif e % 100000 == 0:\n",
    "\t\t\t\tprint(e, reduced, datetime.now() - start)\n",
    "\tprint(e, reduced, datetime.now() - start)\n",
    "\n",
    "def diff_days(s1,s2):\n",
    "    #將日期字串轉換成日期格式\n",
    "\tdate_format = \"%Y-%m-%d\"\n",
    "\ta = datetime.strptime(s1, date_format)\n",
    "\tb = datetime.strptime(s2, date_format)\n",
    "\tdelta = b - a\n",
    "    #回傳天數差\n",
    "\treturn delta.days\n",
    "\n",
    "def generate_features(transactions_file, out_file):\n",
    "\t#keep a dictionary with the offerdata\n",
    "\toffers = {}\n",
    "\toffers_categories = {}\n",
    "\toffers_companies = {}\n",
    "\tfor e, line in enumerate( open(offers_file) ):\n",
    "\t\trow = line.strip().split(\",\")\n",
    "\t\toffers[ row[0] ] = row\n",
    "\t\toffers_categories[row[1]] = 1\n",
    "\t\toffers_companies[row[3]] = 1\n",
    "\n",
    "\t# dicts with variables from history\n",
    "\tids = {}\n",
    "\tfor e, line in enumerate( open(history_file) ):\n",
    "\t\tif e > 0:\n",
    "\t\t\trow = line.strip().split(\",\")\n",
    "\t\t\tids[row[0]] = row\n",
    "\n",
    "\tseen_ids = set([])\n",
    "\n",
    "\toutfile = open(out_file, \"wb\")\n",
    "\toutfile.write(\"label repeattrips id \"+\" \".join(feature_list)+\" market chain\\n\")\n",
    "\t\n",
    "\t#iterate through reduced dataset\n",
    "\tlast_id = 0\n",
    "\tfeatures = defaultdict(float)\n",
    "\tfor e, line in enumerate( open(transactions_file) ):\n",
    "\t\tif e > 0: #skip header\n",
    "\t\t\t#poor man's csv reader\n",
    "\t\t\trow = line.strip().split(\",\")\n",
    "\t\t\t#write away the features when we get to a new shopper id\n",
    "\t\t\tif last_id != row[0] and e != 1:\n",
    "\t\t\t\t\n",
    "\t\t\t\t#generate negative features\n",
    "\t\t\t\tif \"has_bought_company\" not in features:\n",
    "\t\t\t\t\tfeatures['never_bought_company'] = 1\n",
    "\t\t\t\t\n",
    "\t\t\t\tif \"has_bought_category\" not in features:\n",
    "\t\t\t\t\tfeatures['never_bought_category'] = 1\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tif \"has_bought_brand\" not in features:\n",
    "\t\t\t\t\tfeatures['never_bought_brand'] = 1\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tif \"has_bought_brand\" in features and \"has_bought_category\" in features and \"has_bought_company\" in features:\n",
    "\t\t\t\t\tfeatures['has_bought_brand_company_category'] = 1\n",
    "\t\t\t\t\n",
    "\t\t\t\tif \"has_bought_brand\" in features and \"has_bought_category\" in features:\n",
    "\t\t\t\t\tfeatures['has_bought_brand_category'] = 1\n",
    "\t\t\t\t\n",
    "\t\t\t\tif \"has_bought_brand\" in features and \"has_bought_company\" in features:\n",
    "\t\t\t\t\tfeatures['has_bought_brand_company'] = 1\n",
    "\t\t\t\t\t\n",
    "\t\t\t\toutline = \"\"\n",
    "\t\t\t\tif not testset and last_id in ids:\n",
    "\t\t\t\t\toutline += str(features[\"label\"]) + \" \" + ids[last_id][4] + \" \" + str(last_id)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\toutline += \"-1 -1 \"+str(last_id)\n",
    "\t\t\t\tfor l in feature_list:\n",
    "\t\t\t\t\tif l in features:\n",
    "\t\t\t\t\t\toutline += \" \"+str(features[l])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\toutline += \" 0\"\n",
    "\t\t\t\t# write chain and market\n",
    "\t\t\t\tif last_id in ids:\n",
    "\t\t\t\t\toutline += \" \"+ids[last_id][3]\n",
    "\t\t\t\t\toutline += \" \"+ids[last_id][1]\n",
    "\t\t\t\toutline += \"\\n\"\n",
    "\t\t\t\tif last_id in ids:\n",
    "\t\t\t\t\toutfile.write( outline )\n",
    "\t\t\t\t\tseen_ids.add(last_id)\n",
    "\t\t\t\t#reset features\n",
    "\t\t\t\tfeatures = defaultdict(float)\n",
    "\t\t\t#check if we have a valid sample\n",
    "\t\t\tif row[0] in ids:\n",
    "\t\t\t\t#generate label and history\n",
    "\t\t\t\thistory = ids[row[0]]\n",
    "\t\t\t\tif not testset and row[0] in ids:\n",
    "\t\t\t\t\tif ids[row[0]][5] == \"t\":\n",
    "\t\t\t\t\t\tfeatures['label'] = 1\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tfeatures['label'] = 0\n",
    "\t\t\t\t\n",
    "\t\t\t\tfeatures['offer_value'] = offers[ history[2] ][4]\n",
    "\t\t\t\tfeatures['offer_id'] = history[2]\n",
    "\t\t\t\t\n",
    "\t\t\t\toffervalue = offers[ history[2] ][4]\n",
    "\t\t\t\t\n",
    "\t\t\t\tfeatures['total_spend_all'] += float( row[10] )\n",
    "\t\t\t\t\n",
    "\t\t\t\tif row[3] in offers_categories or row[4] in offers_companies:\n",
    "\t\t\t\t\tfeatures['total_spend_ccb'] += float( row[10] )\n",
    "\t\t\t\t\n",
    "\t\t\t\tif offers[ history[2] ][3] == row[4]:\n",
    "\t\t\t\t\tfeatures['has_bought_company'] += 1.0\n",
    "\t\t\t\t\tfeatures['has_bought_company_q'] += float( row[9] )\n",
    "\t\t\t\t\tfeatures['has_bought_company_a'] += float( row[10] )\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tdate_diff_days = diff_days(row[6],history[-1])\n",
    "\t\t\t\t\tif date_diff_days < 30:\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_30'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_q_30'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_a_30'] += float( row[10] )\n",
    "\t\t\t\t\tif date_diff_days < 60:\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_60'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_q_60'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_a_60'] += float( row[10] )\n",
    "\t\t\t\t\tif date_diff_days < 90:\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_90'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_q_90'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_a_90'] += float( row[10] )\n",
    "\t\t\t\t\tif date_diff_days < 180:\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_180'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_q_180'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_company_a_180'] += float( row[10] )\n",
    "\t\t\t\t\n",
    "\t\t\t\tif offers[ history[2] ][1] == row[3]:\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tfeatures['has_bought_category'] += 1.0\n",
    "\t\t\t\t\tfeatures['has_bought_category_q'] += float( row[9] )\n",
    "\t\t\t\t\tfeatures['has_bought_category_a'] += float( row[10] )\n",
    "\t\t\t\t\tdate_diff_days = diff_days(row[6],history[-1])\n",
    "\t\t\t\t\tif date_diff_days < 30:\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_30'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_q_30'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_a_30'] += float( row[10] )\n",
    "\t\t\t\t\tif date_diff_days < 60:\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_60'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_q_60'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_a_60'] += float( row[10] )\n",
    "\t\t\t\t\tif date_diff_days < 90:\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_90'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_q_90'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_a_90'] += float( row[10] )\t\t\t\t\t\t\n",
    "\t\t\t\t\tif date_diff_days < 180:\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_180'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_q_180'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_category_a_180'] += float( row[10] )\t\t\t\t\n",
    "\t\t\t\tif offers[ history[2] ][5] == row[5] and (row[3] in offers_categories or row[4] in offers_companies):\n",
    "\t\t\t\t\tfeatures['has_bought_brand'] += 1.0\n",
    "\t\t\t\t\tfeatures['has_bought_brand_q'] += float( row[9] )\n",
    "\t\t\t\t\tfeatures['has_bought_brand_a'] += float( row[10] )\n",
    "\t\t\t\t\tdate_diff_days = diff_days(row[6],history[-1])\n",
    "\t\t\t\t\tif date_diff_days < 30:\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_30'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_q_30'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_a_30'] += float( row[10] )\n",
    "\t\t\t\t\tif date_diff_days < 60:\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_60'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_q_60'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_a_60'] += float( row[10] )\n",
    "\t\t\t\t\tif date_diff_days < 90:\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_90'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_q_90'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_a_90'] += float( row[10] )\t\t\t\t\t\t\n",
    "\t\t\t\t\tif date_diff_days < 180:\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_180'] += 1.0\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_q_180'] += float( row[9] )\n",
    "\t\t\t\t\t\tfeatures['has_bought_brand_a_180'] += float( row[10] )\t\n",
    "\t\t\tlast_id = row[0]\n",
    "\t\t\tif e % 100000 == 0:\n",
    "\t\t\t\tprint (e)\n",
    "\t# do stuff for ids without transactions\n",
    "\tallids = set(ids.keys())\n",
    "\tunseen_ids = allids.difference(seen_ids)\n",
    "\tfor ui in unseen_ids:\n",
    "\t\tfeatures = defaultdict(float)\n",
    "\t\thistory = ids[ui]\n",
    "\t\tfeatures['offer_value'] = offers[ history[2] ][4]\n",
    "\t\tfeatures['offer_id'] = history[2]\n",
    "\t\tif not testset:\n",
    "\t\t\tif ids[ui][5] == \"t\":\n",
    "\t\t\t\tfeatures['label'] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tfeatures['label'] = 0\n",
    "\t\tif \"has_bought_company\" not in features:\n",
    "\t\t\tfeatures['never_bought_company'] = 1\n",
    "\t\tif \"has_bought_category\" not in features:\n",
    "\t\t\tfeatures['never_bought_category'] = 1\n",
    "\t\tif \"has_bought_brand\" not in features:\n",
    "\t\t\tfeatures['never_bought_brand'] = 1\n",
    "\t\tif \"has_bought_brand\" in features and \"has_bought_category\" in features and \"has_bought_company\" in features:\n",
    "\t\t\tfeatures['has_bought_brand_company_category'] = 1\n",
    "\t\tif \"has_bought_brand\" in features and \"has_bought_category\" in features:\n",
    "\t\t\tfeatures['has_bought_brand_category'] = 1\n",
    "\t\tif \"has_bought_brand\" in features and \"has_bought_company\" in features:\n",
    "\t\t\tfeatures['has_bought_brand_company'] = 1\n",
    "\t\toutline = \"\"\n",
    "\t\tif not testset:\n",
    "\t\t\toutline += str(features[\"label\"]) + \" \" + ids[ui][4] + \" \" + str(ui)\n",
    "\t\telse:\n",
    "\t\t\toutline += \"-1 -1 \"+str(ui)\n",
    "\t\tfor l in feature_list:\n",
    "\t\t\tif l in features:\n",
    "\t\t\t\toutline += \" \"+str(features[l])\n",
    "\t\t\telse:\n",
    "\t\t\t\toutline += \" 0\"\n",
    "\t\t# write chain and market\n",
    "\t\toutline += \" \"+ids[ui][3]\n",
    "\t\toutline += \" \"+ids[ui][1]\n",
    "\t\toutline += \"\\n\"\n",
    "\t\toutfile.write( outline.encode() )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\treduce_data(offers_file, transactions_file, reduced_file)\n",
    "\tgenerate_features(transactions_file, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574c608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
